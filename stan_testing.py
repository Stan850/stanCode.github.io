# -*- coding: utf-8 -*-
"""Stan-Testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qHYY8Kt1TQFRym1RZ8BRW6H5U9ta3kjg
"""

from google.colab import drive

drive.mount('/content/gdrive')

import torch
import csv
import numpy as np
import torch.nn as nn
import torch.optim as optim #for gradient descent
import torch.nn.functional as F
import os
from ast import literal_eval
import math
import torchvision.models
import torchvision
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import time
import glob
import pathlib
import copy
from   copy import deepcopy
import typing
from   typing import List, Tuple, Iterable, Dict
import PIL
from PIL import Image
from torchvision.utils import save_image

base_path = '/content/gdrive/My Drive/aps360/APS360 Content/Stan_Dataset/train'

# df = pd.read_csv(base_path + '/annotations.csv')
filename = ''
data = []
subImg = []
with open(base_path + '/annotations.csv') as csv_file:
  csv_reader = csv.reader(csv_file, delimiter=',')
  next(csv_reader, None)

  for row in csv_reader:
    if row[0] != filename:
      data.append(subImg)
      subImg = []
      filename = row[0] # The filename
      subImg.append(filename)
      subImg.append(row[1]) # The width
      subImg.append(row[2]) # The height
      subImg.append(((row[4], row[5]), (row[6], row[7]), row[3])) #The coordinates for a face in the image
    else:
      subImg.append(((row[4], row[5]), (row[6], row[7]), row[3])) #Coordinates for next face in the same image
  
with open('/content/gdrive/My Drive/aps360/APS360 Content/Stan_Dataset' + 'annotationsTrain.csv', mode='w', newline='') as file:
  file_writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
  for row in data:
    # print(row[0])
    file_writer.writerow(row)
print("data has {} rows".format(len(data)))

# Set up the paths and folders

masterPath = '/content/gdrive/My Drive/aps360/APS360 Content'
imgsPath =  masterPath + '/Adis_dataset/test_set/images'

for state in ['no-mask', 'mask']: 
  folder_name = masterPath + '/' + state
  if not os.path.isdir(folder_name):
    os.mkdir(folder_name)

def ExtractFaces(imgInfo, imgSize):
  newBounds = []
  for boundingBx in imgInfo:
    coords = boundingBx[:-1] # the two corner coords of the bounding box
    coords = [(int(x[0]), int(x[1])) for x in coords]
    center = computeCenter(coords)
    dimX = coords[1][0] - coords[0][0] # (xMax - xMin)
    dimY = coords[1][1] - coords[0][1] # (yMax - yMin)
    if (dimX <= 112 and dimY <= 112):
      largestDim = 112
      gapFrmRightEdge = imgSize[0] - (center[0] + 56)
      gapFrmLeftEdge = center[0] - 56
      newXL, newXR = getPoints(center[0], largestDim, (gapFrmRightEdge, gapFrmLeftEdge), imgSize[0])
      gapFrmBtmEdge = imgSize[1] - (center[1] + 56)
      gapFrmTopEdge = center[1] - 56
      newYT, newYB = getPoints(center[1], largestDim, (gapFrmBtmEdge, gapFrmTopEdge), imgSize[1])

    elif (dimY >= dimX):
      largestDim = dimY # so extend along the x dimension
      gapFrmRightEdge = imgSize[0] - (center[0] + math.floor(largestDim/2))
      gapFrmLeftEdge = center[0] - math.floor(largestDim/2)
      newXL, newXR = getPoints(center[0], largestDim, (gapFrmRightEdge, gapFrmLeftEdge), imgSize[0])
      newYT = coords[0][1]
      newYB = coords[1][1]

    else:
      largestDim = dimX # so extend along the y dimension
      gapFrmBtmEdge = imgSize[1] - (center[1] + math.floor(largestDim/2))
      gapFrmTopEdge = (center[1] - math.floor(largestDim/2))
      newYT, newYB = getPoints(center[1], largestDim, (gapFrmBtmEdge, gapFrmTopEdge), imgSize[1])
      newXL = coords[0][0]
      newXR = coords[1][0]
  
    newBounds.append(((newXL, newYT), (newXR, newYB), boundingBx[-1]))
  return newBounds

#******Miscellaneous*********
    # if (gapFrmBtmEdge < 0):
      #   newYB = imgSize[1]
      #   newYT = imgSize[1] - largestDim
      # elif (gapFrmTopEdge < 0):
      #   newYT = 0
      #   newYB = largestDim
      # else:     
      #   newYT = center[1] - largestDim/2
      #   newYB = center[1] + largestDim/2

def getPoints(middle, largestDim, gaps, imgDim):
    if (gaps[0] < 0):
      point2 = imgDim
      point1 = imgDim - largestDim
    elif (gaps[1] < 0):
      point1 = 0
      point2 = largestDim
    else:
      point1 = middle - math.floor(largestDim/2)
      point2 = middle + math.floor(largestDim/2)
    return point1, point2


def computeCenter(coords):
  xCenter = coords[0][0] + math.floor((coords[1][0] - coords[0][0])/2)
  yCenter = coords[0][1] + math.floor((coords[1][1] - coords[0][1])/2)
  return (xCenter, yCenter)

def getFaces(img, updatedBounds):
  newImgs = []
  for bound in updatedBounds:
    imgCropped = img[bound[0][1]:bound[1][1],bound[0][0]:bound[1][0],:]
    plt.imshow(imgCropped)
    newImgs.append((imgCropped, bound[2]))
  return newImgs

with open(masterPath + '/Adis_dataset/annotations.csv') as csv_file:
  csv_reader = csv.reader(csv_file, delimiter=',')

  imgs = os.listdir(imgsPath)
  imgNums = [int(x.strip('.png')) for x in imgs]

  for row in csv_reader:
    fileNum = int(row[0][12:]) 
    if (fileNum in imgNums):
      ind = imgNums.index(fileNum)
      img = plt.imread(imgsPath + "/{}".format(imgs[ind]))
      # plt.imshow(img)    
    temp = row[5:] # coordinate info for each face
    boundingBxs = [literal_eval(x) for x in temp]
    imgSize = [literal_eval(row[1]), literal_eval(row[2])] # row[1] represents width, row[2] represents height
    updatedBounds = ExtractFaces(boundingBxs, imgSize)
    # print(boundingBxs)
    # print(updatedBounds)
    newImgs = getFaces(img, updatedBounds)
    n = 0
    for croppedImg in newImgs:
      if croppedImg[1] == 'mask':
        plt.imsave(masterPath + '/mask/' + str(fileNum) + '-{}.png'.format(n), croppedImg[0])
      else:
        plt.imsave(masterPath + '/no-mask/' + str(fileNum) + '-{}.png'.format(n), croppedImg[0])
      n+=1
    # break

alexnet = torchvision.models.alexnet(pretrained=True)

from sklearn.model_selection import train_test_split

def getDataLoader(path, val_split, test_split, smallSample, batch_size):
    transform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor()])
    datasets = torchvision.datasets.ImageFolder(root=path, transform=transform)
    print(datasets.class_to_idx)

    # train_idx, val_idx = train_test_split(list(range(len(datasets))), test_size=val_split, shuffle=True)
    # val_idx, test_idx = train_test_split(list(range(len(val_idx))), test_size=test_split, shuffle=True)

    np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling

    indices = list(range(0, len(datasets)))
    np.random.shuffle(indices)
    splitTr = int(0.6*len(datasets))
    splitV = int(0.9*len(datasets))

    train_idx = indices[0:splitTr]
    val_idx = indices[splitTr:splitV]
    test_idx = indices[splitV:]
    
    np.random.shuffle(train_idx)
    np.random.shuffle(val_idx)
    np.random.shuffle(test_idx)

    # The code below is used to extract a smaller set for overfitting tests (sanity checking that our model works)
    if smallSample != 0:
      train_sampler = SubsetRandomSampler(train_idx[0:smallSample])
      val_sampler = SubsetRandomSampler(val_idx[0:smallSample])
      test_sampler = SubsetRandomSampler(test_idx[0:smallSample])
    else:
      train_sampler = SubsetRandomSampler(train_idx)
      val_sampler = SubsetRandomSampler(val_idx)
      test_sampler = SubsetRandomSampler(test_idx)

    print("Train indices length: ", len(train_sampler))
    print("Validation indices length: ", len(val_sampler))
    print("Test indices length: ", len(test_sampler))

    train_loader = torch.utils.data.DataLoader(datasets, batch_size=batch_size,
                                            num_workers=1, sampler=train_sampler)

    val_loader = torch.utils.data.DataLoader(datasets, batch_size=batch_size,
                                            num_workers=1, sampler=val_sampler)
    
    test_loader = torch.utils.data.DataLoader(datasets, batch_size=batch_size,
                                            num_workers=1, sampler=test_sampler)
  
    return train_loader, val_loader, test_loader

def computAlxN_features(data_loader, datasetType):
  master_path = '/content/gdrive/My Drive/aps360/APS360 Content/Stan-AlxFeatures/Balanced'
  # master_path = '/content/gdrive/My Drive/aps360/APS360 Content/Stan_Dataset/StanSplit'
  n = 0
  classes = ['Faces', 'No-faces']
  for img, label in data_loader:
    # print(label)
    features = alexnet.features(img)
    features_tensor = torch.from_numpy(features.detach().numpy())

    # Name the folder created (if it didn't exist previously) to the label
    # corresponding to the feature's image
    folder_name = master_path + '/' + datasetType
    if not os.path.isdir(folder_name):
      os.mkdir(folder_name)
    elif not os.path.isdir(folder_name + '/' + str(classes[label])):
        os.mkdir(folder_name + '/' + str(classes[label]))
    else:
      # save_image(features_tensor.squeeze(0), folder_name + '/' + str(classes[label]) + '/' + str(n) + '.png')
      n += 1
      torch.save(features_tensor.squeeze(0), folder_name + '/' + str(classes[label]) + '/' + str(n) + '.png')

path = '/content/gdrive/My Drive/aps360/APS360 Content/Stan_Dataset/StanBalanced'
train_loader, val_loader, test_loader = getDataLoader(path, 0.3, 0.5, smallSample=0, batch_size = 1)

dataiter = iter(val_loader)
images, labels = dataiter.next()
images = images.numpy() # convert images to numpy for display

classes = ['Faces', 'No-faces']

# code to just plot 20 images from the whole dataset
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(1):
    ax = fig.add_subplot(1, 1, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])

#############################################################################  Old Code ##############################################
masterPath = '/content/gdrive/My Drive/aps360/APS360 Content/Matt_Processed_Dataset/dataset_balanced'
transform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor()])
batch_size = 1

mattTrain = torchvision.datasets.ImageFolder(root= masterPath + '/train', transform=transform)
labels = [1] * len(mattTrain.targets)
mattTrain.targets = labels
mTrain_loader = torch.utils.data.DataLoader(mattTrain, batch_size=batch_size, num_workers=0, shuffle=True)

mattValid = torchvision.datasets.ImageFolder(root= masterPath + '/validate', transform=transform)
labels = [1] * len(mattValid.targets)
mattValid.targets = labels
mVal_loader = torch.utils.data.DataLoader(mattValid, batch_size=batch_size, num_workers=0, shuffle=True)

mattTest = torchvision.datasets.ImageFolder(root= masterPath + '/test', transform=transform)
labels = [1] * len(mattTrain.targets)
mattTest.targets = labels
mTest_loader = torch.utils.data.DataLoader(mattTest, batch_size=batch_size, num_workers=0, shuffle=True)

computAlxN_features(train_loader, 'train', 'No-faces')
computAlxN_features(val_loader, 'validate', 'No-faces')
computAlxN_features(test_loader, 'test', 'No-faces')

print("Done computing AlexNet features for No-faces. Computing features for faces now...")

computAlxN_features(mTrain_loader, 'train', 'faces')
computAlxN_features(mVal_loader, 'validate', 'faces')
computAlxN_features(mTest_loader, 'test', 'faces')

print("Done computing AlexNet features for faces")
n = 0
for imgs, labels in mTrain_loader:
  if n > 1:
    break
  else:
    print(imgs.shape)
    print(labels.shape)
    n+=1

computAlxN_features(train_loader, 'train')
print("Done computing training alex features. Computing validation alex features now...")
computAlxN_features(val_loader, 'validate')
print("Done computing validation alex features. Computing testing features now...")
computAlxN_features(test_loader, 'test')
print("Done computing features")

# alxPath = '/content/gdrive/My Drive/aps360/APS360 Content/Stan-AlxFeatures/Balanced'
testPath = '/content/gdrive/My Drive/aps360/APS360 Content/Stan_Dataset/StanSplit'

def createFeatureLoaders(path, dataType, batch_size):

  datasets = torchvision.datasets.DatasetFolder(path + '/' + dataType, loader=torch.load, extensions=('.tensor'))
  # datasets = torchvision.datasets.ImageFolder(root=path + '/' + dataType)
  data_loader = torch.utils.data.DataLoader(datasets, batch_size=batch_size,
                                              num_workers=0, shuffle=True)
  return data_loader
  
train_features = createFeatureLoaders(testPath, 'train', 100)
val_features = createFeatureLoaders(testPath, 'validate', 100)
test_features = createFeatureLoaders(testPath, 'test', 100)
print(len(train_features))
print(len(val_features))
print(len(test_features))

n = 0
for img, labels in train_features:
  print(img.shape)
  print(labels.shape)
  if n > 5:
    break
  n+=1

class ANN_v1(nn.Module):

    #initialize NN instance
    def __init__(self,
                       output_size:        int = 2,  
                      #  lin_activation_func     = lambda: nn.ReLU()):
                       lin_activation_func     = lambda: nn.LeakyReLU(0.2)):
                      #  out_activation_func     = lambda: nn.Softmax(dim = 1)): 
                      #  compute_alexnet:bool    = False):

        super(ANN_v1, self).__init__()

        # self.alexnet = torchvision.models.alexnet(pretrained = True)
        self.input_size         = int(256)
        self.output_size        = int(output_size)
        # self.compute_alexnet    = compute_alexnet


        #compute input size for ANN (MLP)
        self.flatten_size = int(256*6*6)
        # print(self.flatten_size)

        #MLP section
        self.fully_connected_section = nn.Sequential(
            # nn.Dropout(0.1),
            nn.Linear(self.flatten_size, 60),
            lin_activation_func(),
            # nn.Dropout(0.1),
            nn.Linear(60, 12),
            lin_activation_func(),
            # nn.Dropout(0.1),
            nn.Linear(12, self.output_size))
            # out_activation_func())

    #perform a forward pass
    def forward(self, x):

        # if self.compute_alexnet: 
        #     x = self.alexnet.features(x)

        x = x.view(-1, self.flatten_size)
        x = self.fully_connected_section(x)
        return x

class Pair_List():
    __slots__ = ['__x_vals', '__y_vals']

    def __init__(self):
        self.__x_vals: list = []
        self.__y_vals: list = []

    def __len__(self)->int:
        return int(len(self.__x_vals))

    def __getitem__(self, index: int)->tuple:
        return copy.deepcopy(self.__x_vals[index]), copy.deepcopy(self.__y_vals[index])

    def append(self, x, y)->None:
        self.__x_vals.append(x)
        self.__y_vals.append(y)
    
    def clear(self, x, y)->None:
        del self.__x_vals
        del self.__y_vals
        self.__x_vals = []
        self.__y_vals = []

    def pop(self, index: int)->None:
        index = int(index)
        self.__x_vals.pop(index)
        self.__y_vals.pop(index)

    def split_list(self)->Tuple[list, list]:
        return copy.deepcopy(self.__x_vals), copy.deepcopy(self.__y_vals)

def train_network(network, training_loader,       validation_loader, 
                           batch_size: int,       learning_rate: float = 0.0005, 
                           num_epochs: int  = 10, momentum:      float = 0.9, 
                           batches_per_loss_calc:     int = 10, 
                           batches_per_accuracy_calc: int = 10,
                           use_cuda:   bool = False):

    loss_func  = nn.CrossEntropyLoss()
    optimizer  = optim.SGD(network.parameters(), lr=learning_rate, momentum=0.9)

    loss_batch_count = int(0)
    accu_batch_count = int(0)

    train_loss_list = Pair_List()
    train_accu_list = Pair_List()
    valid_loss_list = Pair_List()
    valid_accu_list = Pair_List()

    dp: int = 5 #decimal precision
    curr_iteration = int(0)

    print('----- Training Start -----\n\n')
    #perform complete iterations over training data
    for epoch_num in range(num_epochs):

        #for each batch in training data
        for batch in training_loader:

            images, labels = batch
            #move images and labels to GPU if requested
            if use_cuda:
                images = images.cuda()
                labels = labels.cuda()

            #zero gradients between forward passes
            optimizer.zero_grad()

            #perform forward pass
            net_output = network(images)
            
            #get loss on output
            net_loss   = loss_func(net_output, labels)

            #update weights using backpropagation 
            net_loss.backward()
            optimizer.step()

            loss_batch_count+=1
            accu_batch_count+=1
            curr_iteration+=1
            #print(curr_iteration)

            if loss_batch_count == batches_per_loss_calc:
                train_loss_list.append(curr_iteration, get_network_loss(network, training_loader,   loss_func, use_cuda))
                valid_loss_list.append(curr_iteration, get_network_loss(network, validation_loader, loss_func, use_cuda))
                loss_batch_count = int(0)

            if accu_batch_count == batches_per_accuracy_calc:
                train_accu_list.append(curr_iteration, get_network_accuracy(network, training_loader, use_cuda))
                valid_accu_list.append(curr_iteration, get_network_accuracy(network, validation_loader, use_cuda))
                accu_batch_count = int(0)

        #display training progress
        print(f'Epoch Num: {epoch_num}')
        print(f'Train Accu: {train_accu_list[-1][1]:.{dp}f}, Train Loss: {train_loss_list[-1][1]:.{dp}f}')
        print(f'Valid Accu: {valid_accu_list[-1][1]:.{dp}f}, Valid Loss: {valid_loss_list[-1][1]:.{dp}f}\n')    

    print('----- Training Complete -----')

    return train_accu_list, train_loss_list, valid_accu_list, valid_loss_list

def get_network_accuracy(network, data_loader, use_cuda: bool = True)->float:

    correct_sum = int(0)
    image_sum   = int(0)

    for batch in data_loader:
        
        images, labels = batch
        if use_cuda:
            images = images.cuda()
            labels = labels.cuda()

        net_out          = network(images)
        predicted_labels = net_out.max(1, keepdim = True)[1]
    
        predicted_labels = predicted_labels.squeeze(1)
        correct_sum += int(predicted_labels.eq(labels).sum().item())
        image_sum   += int(len(images))

    return float(correct_sum / image_sum)

def get_network_loss(network, data_loader, loss_func, use_cuda: bool = True)->float:

    loss_sum = float(0.0)

    for i, batch in enumerate(data_loader):
        images, labels = batch
        if use_cuda:
            images = images.cuda()
            labels = labels.cuda()

        net_out  = network(images)
        loss_sum = loss_func(net_out, labels)
    
    return float(loss_sum / (i+1))

def plot_accuracy_curve(training_accuracy:   Pair_List, 
                        validation_accuracy: Pair_List,
                        save_path:str = None):
    t_x, t_y = training_accuracy.split_list()
    v_x, v_y = validation_accuracy.split_list()

    plt.plot(t_x, t_y, label="Training")
    plt.plot(v_x, v_y, label="Validation")
    plt.title("Training vs Validation Accuracy")
    plt.xlabel("Iteration")
    plt.ylabel("Accuracy")
    plt.legend(loc='best')

    if save_path is not None:
        plt.savefig(save_path, dpi = 300)
        plt.close()
    #plt.show()

def plot_loss_curve(training_loss: Pair_List,
                    validation_loss: Pair_List,
                    save_path: str = None):
    t_x, t_y = training_loss.split_list()
    v_x, v_y = validation_loss.split_list()

    plt.plot(t_x, t_y, label="Training")
    plt.plot(v_x, v_y, label="Validation")
    plt.title("Training vs Validation Loss")
    plt.xlabel("Iteration")
    plt.ylabel("Loss")
    plt.legend(loc='best')

    if save_path is not None:
        plt.savefig(save_path, dpi = 300)
        plt.close()
    #plt.show()

########################################## With new updated datasets ##################################################

torch.cuda.empty_cache()

net = ANN_v1()
net.to('cuda')

batches_per = int(len(train_features)/6)

learning_rate = 0.00025
num_epochs    = 40
batch_size = 100

train_accu, train_loss, valid_accu, valid_loss = train_network(net, train_features, val_features, 
            batch_size=batch_size, learning_rate=learning_rate, num_epochs=num_epochs, momentum=0.9, 
            batches_per_loss_calc=batches_per, batches_per_accuracy_calc=batches_per, use_cuda=True)


torch.save(net.state_dict(), f'/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Stan-Weights/WithLeaky.pth')

save_accu_path = f'/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Curves/accu_Lk({learning_rate:.6f})_epoch({num_epochs})_bsize({batch_size}).png'
save_loss_path = f'/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Curves/loss_Lk({learning_rate:.6f})_epoch({num_epochs})_bsize({batch_size}).png'

plot_accuracy_curve(train_accu, valid_accu, save_accu_path)
plot_loss_curve(train_loss, valid_loss, save_loss_path)

def get_all_preds(model, loader):
    predTotal = torch.tensor([])
    for batch in loader:
        images, labels = batch

        preds = model(images)
        predTotal = torch.cat(
            (predTotal, preds)
            ,dim=0
        )
    return predTotal

with torch.no_grad():
    network = ANN_v1()
    network.load_state_dict(torch.load("/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Stan-Weights/updated_cnn0.9865996649916248.pth"))
    training_set = torchvision.datasets.DatasetFolder(alxPath + '/' + 'train', loader=torch.load, extensions=('.tensor'))
    train_preds = get_all_preds(network, training_set)
                                
print(training_set.targets)
print(train_preds.argmax(dim=1))

import matplotlib.pyplot as plt

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(training_set.targets, train_preds.argmax(dim=1))
print(type(cm))

import itertools
# import numpy as np
import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')

plt.figure(figsize=(10,10))
plot_confusion_matrix(cm, training_set.classes)
plt.savefig("/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Stan-ConfusionMatrix/cmBal.png")

# ##########################An earlier run with the old datasets ###################################
torch.cuda.empty_cache()

net = ANN_v1()
net.to('cuda')

batches_per = int(len(train_features)/6)

learning_rate = 0.00025
num_epochs    = 40
batch_size = 100

train_accu, train_loss, valid_accu, valid_loss = train_network(net, train_features, val_features, 
            batch_size=batch_size, learning_rate=learning_rate, num_epochs=num_epochs, momentum=0.9, 
            batches_per_loss_calc=batches_per, batches_per_accuracy_calc=batches_per, use_cuda=True)


# torch.save(net.state_dict(), f'images/new_dataset/net_weights/net_valid_{valid_accu[-1][1]}.pth')

# save_accu_path = f'images/new_dataset/net_weights/accu_lr({learning_rate:.6f})_epoch({num_epochs})_bsize({batch_size}).png'
# save_loss_path = f'images/new_dataset/net_weights/loss_lr({learning_rate:.6f})_epoch({num_epochs})_bsize({batch_size}).png'

plot_accuracy_curve(train_accu, valid_accu)
plot_loss_curve(train_loss, valid_loss)

s = nn.Softmax(dim = 1)
test_features = createFeatureLoaders(alxPath, 'test', 4)
test = iter(test_features)
images, labels = test.next()
images = images.cuda()
labels = labels.cuda()
output = net(images)
prob = s(output)

print(prob)
print(labels)

transform = transforms.Compose(
        [transforms.Resize([224, 224]), transforms.ToTensor(),
         ])
# Load gesture images
tests = torchvision.datasets.ImageFolder(root='/content/gdrive/My Drive/aps360/APS360 Content/Dataset-NoFaces/testing', transform=transform)
print(tests.class_to_idx)
batch_size = 6
num_workers = 0
sample_loader = torch.utils.data.DataLoader(tests, batch_size=batch_size, 
                                           num_workers=num_workers, shuffle=False)

dataiter = iter(sample_loader)
images, labels = dataiter.next()
images = images.numpy() # convert images to numpy for display

classes = ['No-faces', 'faces']
# classes = ['faces']

# code to just plot 20 images from the whole dataset
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(6):
    ax = fig.add_subplot(1, 6, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])

ALNC = alexnet.features
ALNC.cuda()
s = nn.Softmax(dim = 1)
net = ANN_v1()
net.load_state_dict(torch.load("/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Stan-Weights/WithLeaky.pth"))
net.to('cuda')
fig = plt.figure(figsize=(25, 4))

with torch.no_grad():
  test = iter(sample_loader)
  images, labels = test.next()
  for idx in np.arange(3):
    ax = fig.add_subplot(1, 3, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])
  images = images.cuda()
  labels = labels.cuda()
      #############################################
  output = net(ALNC(images))
  prob = s(output)

print(prob)
print(labels)

ALNC = alexnet.features
ALNC.cuda()
s = nn.Softmax(dim = 1)
net = ANN_v1()
net.load_state_dict(torch.load("/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Stan-Weights/updated_cnn0.9865996649916248.pth"))
net.to('cuda')
with torch.no_grad():
  test = iter(sample_loader)
  images, labels = test.next()

  images = images.cuda()
  labels = labels.cuda()
      #############################################
  output = net(ALNC(images))
  prob = s(output)

print(prob)
print(labels)

# My own code from Lab3
def getAlex_accuracy(model, loader):

    correct = 0
    total = 0
    for alxImgs, labels in loader:
            
        #############################################
        #To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
          alxImgs = alxImgs.cuda()
          labels = labels.cuda()
        #############################################
        output = model(alxImgs)
 
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += alxImgs.shape[0]

    return correct / total
    
def alexTrain(model, batch_size=100, num_epochs=1):

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.015, momentum=0.9)

    iters, losses, train_acc, val_acc = [], [], [], []

    # training
    n = 0 # the number of iterations
    start_time=time.time()
    for epoch in range(num_epochs):
        mini_b=0
        mini_batch_correct = 0
        Mini_batch_total = 0
  
        for imgs, labels in train_features:
          
            
            #############################################
            #To Enable GPU Usage
            if use_cuda and torch.cuda.is_available():
              imgs = imgs.cuda()
              labels = labels.cuda()
            #############################################

            out = model(imgs)

            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch


            # To save time, I computed the training accuracy for the mini batch
            # each iteration instead of iterating through all batches of my training set to compute the accuracy

            pred = out.max(1, keepdim=True)[1]
            mini_batch_correct = pred.eq(labels.view_as(pred)).sum().item()
            Mini_batch_total = imgs.shape[0]
            train_acc.append((mini_batch_correct / Mini_batch_total))
          
           ###########################

            iters.append(n)
            losses.append(float(loss)/batch_size)             # compute *average* loss
            val_acc.append(getAlex_accuracy(model, val_features))
            n += 1
            mini_b += 1
            print("Iteration: ",n,'Progress: % 6.2f ' % ((epoch * len(train_features) + mini_b) / (num_epochs * len(train_features))*100),'%', "Time Elapsed: % 6.2f s " % (time.time()-start_time))


        print ("Epoch %d Finished. " % epoch ,"Time per Epoch: % 6.2f s "% ((time.time()-start_time) / (epoch +1)))


    end_time= time.time()
    # plotting
    plt.title("Training Curve")
    plt.plot(iters, losses, label="Train")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()

    plt.title("Training Curve")
    plt.plot(iters, train_acc, label="Training")
    plt.plot(iters, val_acc, label="Validation")    
    plt.xlabel("Iterations")
    plt.ylabel("Validation Accuracy")
    plt.legend(loc='best')
    plt.show()

    train_acc.append(getAlex_accuracy(model, train_features))
    print("Final Training Accuracy: {}".format(train_acc[-1]))
    print("Final Validation Accuracy: {}".format(val_acc[-1]))
    print ("Total time:  % 6.2f s  Time per Epoch: % 6.2f s " % ( (end_time-start_time), ((end_time-start_time) / num_epochs) ))

use_cuda = True
model = ANN_v1()
ALNC = alexnet.features

if use_cuda and torch.cuda.is_available():
  ALNC.cuda()
  model.cuda()
  print('CUDA is available!  Training on GPU ...')
else:
  print('CUDA is not available.  Training on CPU ...')

alexTrain(model, batch_size = 100, num_epochs=50)

path = '/content/gdrive/MyDrive/aps360/PNGImages'
imgNames = os.listdir(path)
sorted(imgNames)

import re

def getPplBounds(path):
  annoPath = path
  personBounds = []
  for line in open(annoPath):
    if (line.split(' ')[0] == 'Bounding'):
      line = line[line.find(':'):len(line)]
      x = re.findall("(\(\d+\, \d+\))", line)
      personBounds.append((literal_eval(x[0]), literal_eval(x[1])))
  return(personBounds)

def getCroppedImgs(_bounds, imgSize):
  croppedImgs = []
  for i in _bounds:
    xMin = i[0][0]
    xMax = i[1][0]
    yTop = i[0][1]
    yBottom = i[1][1]
    personW = xMax - xMin
    personH = math.ceil(personW/2)
    # print(personW)
    bottomLim = yTop + personH
    yBnd = bottomLim + personW
    while (yBnd <= imgSize[1] and (yBnd - personW) < yBottom):
      im = image.crop((xMin, yBnd - personW, xMax, yBnd))
      print(im.size)
      newsize = (224, 224) 
      im = im.resize(newsize, PIL.Image.LANCZOS) 
      croppedImgs.append(im)
      yBnd += personW
  return(croppedImgs)

# BasePaths
AnnoPath = '/content/gdrive/MyDrive/aps360/Annotation/'
ImgsPath = '/content/gdrive/MyDrive/aps360/PNGImages/'
imgNames = os.listdir(ImgsPath)
imgNames = sorted(imgNames)
allImgs = []
# image
for img in imgNames:
  image = Image.open(ImgsPath + '/' + img)
  path = AnnoPath + img.rstrip('.png') + '.txt'
  bounds = getPplBounds(path)
  imgs = getCroppedImgs(bounds, image.size)
  allImgs += imgs
  image.close()

print(len(allImgs))

allImgs[608]

pathNoFaces = '/content/gdrive/MyDrive/aps360/No-faces/'
num = 0
for pic in allImgs:
  pic.save(pathNoFaces + "{}.jpg".format(num))
  num +=1
print("Done saving images")

ALNC = alexnet.features
ALNC.cuda()
s = nn.Softmax(dim = 1)
net = ANN_v1()
net.load_state_dict(torch.load("/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Stan-Weights/WithLeaky.pth"))
net.to('cuda')

with torch.no_grad():
  acc = get_network_accuracy(net, test_features)
  print(acc)

transform = transforms.Compose(
        [transforms.Resize([224, 224]), transforms.ToTensor(),
         ])
# Load gesture images
tests = torchvision.datasets.ImageFolder(root='/content/gdrive/My Drive/aps360/APS360 Content/Stan_Dataset/StanSplit/train', transform=transform)
print(tests.class_to_idx)
batch_size = 3
num_workers = 0
sample_loader = torch.utils.data.DataLoader(tests, batch_size=batch_size, 
                                           num_workers=num_workers, shuffle=True)
ALNC = alexnet.features
ALNC.cuda()
s = nn.Softmax(dim = 1)
net = ANN_v1()
net.load_state_dict(torch.load("/content/gdrive/MyDrive/aps360/APS360 Content/Stan-Model/Stan-Weights/WithLeaky.pth"))
net.to('cuda')
test = iter(sample_loader)

classes = ['Faces', 'No-faces']

# code to just plot 20 images from the whole dataset
fig = plt.figure(figsize=(25, 4))

with torch.no_grad():
  images, labels = test.next()
  for idx in np.arange(3):
    ax = fig.add_subplot(1, 3, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])
  images = images.cuda()
  labels = labels.cuda()
      #############################################
  output = net(ALNC(images))
  prob = s(output)
  print(prob)
  print(labels)